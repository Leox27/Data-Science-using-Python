





import os, glob, json, math, warnings, itertools, textwrap

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay
from sklearn.ensemble import RandomForestClassifier

from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.seasonal import seasonal_decompose

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

# Matplotlib fig
plt.rcParams['figure.figsize'] = (10, 5)





df = pd.read_csv("blood_donor_dataset.csv")

df.head()





# Columns likely to be PII
pii_cols = ['name','email','password','contact_number']
cols_to_keep = [c for c in df.columns if c not in pii_cols]
df = df[cols_to_keep].copy()

# Parse dates if present
date_cols = []
for c in df.columns:
    if 'date' in c.lower() or c.lower().endswith('_at'):
        date_cols.append(c)
for c in date_cols:
    try:
        df[c] = pd.to_datetime(df[c], errors='coerce')
    except Exception:
        pass

# Basic structure
display(df.head())
display(df.dtypes.to_frame('dtype').T)
print('Rows:', len(df))
print('Missing by column:\n', df.isna().sum())






# Drop duplicate rows
before = len(df)
df = df.drop_duplicates().copy()
print(f'Dropped {before - len(df)} duplicate rows')

# Donor ID uniqueness check (if present)
if 'donor_id' in df.columns:
    nunique = df['donor_id'].nunique()
    print('Unique donor_id:', nunique, ' / rows:', len(df))

# Derive time features
if 'created_at' in df.columns and pd.api.types.is_datetime64_any_dtype(df['created_at']):
    df['year'] = df['created_at'].dt.year
    df['month'] = df['created_at'].dt.month
    df['year_month'] = df['created_at'].dt.to_period('M').astype(str)

# Ensure numeric types are correct
for num_col in ['months_since_first_donation','number_of_donation','pints_donated']:
    if num_col in df.columns:
        df[num_col] = pd.to_numeric(df[num_col], errors='coerce').astype('Int64')

# Save a cleaned, PII-stripped copy (optional)
clean_path = 'blood_donor_clean.csv'
df.to_csv(clean_path, index=False)
print('Saved cleaned dataset to', clean_path)





# Blood group distribution by Bar plot -
if 'blood_group' in df.columns:
    bg_counts = df['blood_group'].value_counts().sort_index()
    ax = bg_counts.plot(kind='bar')
    
    ax.set_title('Blood Group Distribution')
    ax.set_xlabel('Blood Group')
    ax.set_ylabel('Count')
    ax.legend()
    plt.show()


# Availability distribution -
if 'availability' in df.columns:
    avail_counts = df['availability'].value_counts()
    ax = avail_counts.plot(kind='bar')
    # ax = avail_counts.plot(kind='line') No use
    
    ax.set_title('Availability (Yes/No)')
    ax.set_xlabel('Availability')
    ax.set_ylabel('Count')
    plt.show()


# Top cities who have much Donors
if 'city' in df.columns:
    city_counts = df['city'].value_counts().head(15)
    ax = city_counts.plot(kind='bar')
    
    ax.set_title('Top Cities by Donors')
    ax.set_xlabel('City')
    ax.set_ylabel('Count')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()


# Relationship: number_of_donation vs. pints_donated
if all(c in df.columns for c in ['number_of_donation','pints_donated']):
    ax = df.plot(kind='scatter', x='number_of_donation', y='pints_donated', alpha=0.5) # x & y both are inputs from c from col.
    
    ax.set_title('Donations vs. Pints Donated')
    plt.show()






ts = None
if 'created_at' in df.columns and pd.api.types.is_datetime64_any_dtype(df['created_at']):
    monthly = df.set_index('created_at').resample('MS')['donor_id' if 'donor_id' in df.columns else df.columns[0]].count()
    monthly.name = 'new_donors'
    ts = monthly
    display(monthly.head())

    ax = monthly.plot()
    ax.set_title('Monthly New Donors')
    ax.set_xlabel('Month')
    ax.set_ylabel('Count')
    plt.show()

    # Seasonal decomposition
    if len(monthly) >= 36:
        result = seasonal_decompose(monthly, period=12, model='additive', extrapolate_trend='freq')
        
        result.trend.plot(title='Trend', color='black')
        plt.legend()
        plt.show()
        
        result.seasonal.plot(title='Seasonality', color='red')
        plt.legend()
        plt.show()
        
        result.resid.plot(title='Residuals', color='blue')
        plt.legend()
        plt.show()





from math import sqrt

def rmse(a, f):
    return sqrt(np.mean((np.array(a)-np.array(f))**2))

forecast_path = 'monthly_new_donors_forecast.csv'

if ts is not None and len(ts) >= 24:
    train = ts.iloc[:-12]
    test  = ts.iloc[-12:]

    model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=12, initialization_method='estimated')
    fit = model.fit(optimized=True)
    pred = fit.forecast(12)

    # Evaluation
    eval_rmse = rmse(test.values, pred.values)
    eval_mape = np.mean(np.abs((test.values - pred.values) / np.maximum(test.values, 1))) * 100.0
    print({'RMSE': round(eval_rmse,2), 'MAPE_%': round(eval_mape,2)})

    # Plot test vs forecast
    ax = train.plot(label='train')
    test.plot(ax=ax, label='test')
    pred.plot(ax=ax, label='forecast')
    ax.set_title('Holdout Test & Forecast (12 months)')
    ax.legend()
    plt.show()

    # Refit full and forecast next 12
    model_full = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=12, initialization_method='estimated')
    fit_full = model_full.fit(optimized=True)
    fcst = fit_full.forecast(12)

    # Plot full series with forecast
    ax = ts.plot(label='history')
    fcst.plot(ax=ax, label='12‑mo forecast')
    ax.set_title('Monthly New Donors — 12‑Month Forecast')
    ax.legend()
    plt.show()

    out = pd.DataFrame({'month': fcst.index.to_period('M').astype(str), 'forecast_new_donors': fcst.values})
    out.to_csv(forecast_path, index=False)
    print('Saved forecast ->', forecast_path)
else:
    print('Not enough data to forecast.')





target_col = 'availability'
feature_cols = [c for c in ['months_since_first_donation','number_of_donation','pints_donated','blood_group','city'] if c in df.columns]

if target_col in df.columns and feature_cols:
    data = df[feature_cols + [target_col]].dropna().copy()
    # Map target to binary
    data[target_col] = data[target_col].map({'Yes':1, 'No':0}).astype(int)

    X = data[feature_cols]
    y = data[target_col]

    numeric_features = [c for c in feature_cols if str(X[c].dtype)[:3] in ['int','flo']]
    categorical_features = [c for c in feature_cols if c not in numeric_features]

    pre = ColumnTransformer([
        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ], remainder='passthrough')

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)

    # Logistic Regression
    logit = Pipeline(steps=[('pre', pre), ('clf', LogisticRegression(max_iter=1000))])
    logit.fit(X_train, y_train)
    preds_logit = logit.predict(X_test)
    proba_logit = logit.predict_proba(X_test)[:,1]

    print('Logistic Regression Metrics')
    print(classification_report(y_test, preds_logit, digits=3))
    print('ROC-AUC:', round(roc_auc_score(y_test, proba_logit), 3))

    RocCurveDisplay.from_predictions(y_test, proba_logit)
    plt.title('ROC Curve — Logistic Regression')
    plt.show()

    # Random Forest
    rf = Pipeline(steps=[('pre', pre), ('clf', RandomForestClassifier(n_estimators=300, random_state=RANDOM_SEED))])
    rf.fit(X_train, y_train)
    preds_rf = rf.predict(X_test)
    proba_rf = rf.predict_proba(X_test)[:,1]

    print('Random Forest Metrics')
    print(classification_report(y_test, preds_rf, digits=3))
    print('ROC-AUC:', round(roc_auc_score(y_test, proba_rf), 3))

    RocCurveDisplay.from_predictions(y_test, proba_rf)
    plt.title('ROC Curve — Random Forest')
    plt.show()

    # Feature importances (approximate, post-encoding)
    # Extract from RF pipeline
    rf_model = rf.named_steps['clf']
    # After ColumnTransformer, get feature names:
    oh_names = list(rf.named_steps['pre'].named_transformers_['onehot'].get_feature_names_out(categorical_features)) if categorical_features else []
    final_feature_names = oh_names + numeric_features
    importances = getattr(rf_model, 'feature_importances_', None)
    if importances is not None:
        imp_df = pd.DataFrame({'feature': final_feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(20)
        display(imp_df)
        ax = imp_df.set_index('feature')['importance'].plot(kind='bar')
        ax.set_title('Top Feature Importances — Random Forest')
        ax.set_ylabel('Importance')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

else:
    print('Availability prediction skipped (missing target/feature columns). Found features:', feature_cols, 'Target present?', target_col in df.columns)






