{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f520577",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ©¸ Blood Donation â€” EDA, Forecasting, and Availability Prediction\n",
    "\n",
    "**Goal:** Endâ€‘toâ€‘end, reproducible analysis you can run on Kaggle to:\n",
    "1) Explore the data and clean PII\n",
    "2) Understand donor & blood group distributions\n",
    "3) Analyze monthly donor signâ€‘ups and forecast next 12 months\n",
    "4) Predict donor **availability (Yes/No)** from profile features\n",
    "\n",
    "> **How to use on Kaggle:** Add your dataset (containing `blood_donor_dataset.csv`) to the notebook. The loader below will autoâ€‘discover the file inside `/kaggle/input/â€¦`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031bf4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 1) Setup & Imports\n",
    "# =========================\n",
    "import os, glob, json, math, warnings, itertools, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Matplotlib defaults (no style or colors set per Kaggle-safe, reproducible plots)\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 2) Load Data (auto-discovery)\n",
    "# =========================\n",
    "def find_dataset(filename='blood_donor_dataset.csv'):\n",
    "    # Try Kaggle input path\n",
    "    candidates = glob.glob('/kaggle/input/**/' + filename, recursive=True)\n",
    "    # Fallback to local paths\n",
    "    candidates += glob.glob('**/' + filename, recursive=True)\n",
    "    return candidates[0] if candidates else filename\n",
    "\n",
    "DATA_PATH = find_dataset()\n",
    "print('Using file:', DATA_PATH)\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "print('Shape:', df_raw.shape)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34439a8",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Data Overview & Privacy\n",
    "\n",
    "We remove personally identifiable information (PII) before any analysis or sharing. We keep only analytical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a16614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columns likely to be PII\n",
    "pii_cols = ['name','email','password','contact_number']\n",
    "cols_to_keep = [c for c in df_raw.columns if c not in pii_cols]\n",
    "df = df_raw[cols_to_keep].copy()\n",
    "\n",
    "# Parse dates if present\n",
    "date_cols = []\n",
    "for c in df.columns:\n",
    "    if 'date' in c.lower() or c.lower().endswith('_at'):\n",
    "        date_cols.append(c)\n",
    "for c in date_cols:\n",
    "    try:\n",
    "        df[c] = pd.to_datetime(df[c], errors='coerce')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Basic structure\n",
    "display(df.head())\n",
    "display(df.dtypes.to_frame('dtype').T)\n",
    "print('Rows:', len(df))\n",
    "print('Missing by column:\\n', df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1e2ce",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Basic Cleaning & Feature Engineering\n",
    "- Drop exact duplicate rows (if any)\n",
    "- Ensure `donor_id` uniqueness\n",
    "- Create time-based fields from `created_at` (Year/Month) for time-series\n",
    "- Keep numeric features as integers where applicable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6227d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop duplicate rows\n",
    "before = len(df)\n",
    "df = df.drop_duplicates().copy()\n",
    "print(f'Dropped {before - len(df)} duplicate rows')\n",
    "\n",
    "# Donor ID uniqueness check (if present)\n",
    "if 'donor_id' in df.columns:\n",
    "    nunique = df['donor_id'].nunique()\n",
    "    print('Unique donor_id:', nunique, ' / rows:', len(df))\n",
    "\n",
    "# Derive time features\n",
    "if 'created_at' in df.columns and pd.api.types.is_datetime64_any_dtype(df['created_at']):\n",
    "    df['year'] = df['created_at'].dt.year\n",
    "    df['month'] = df['created_at'].dt.month\n",
    "    df['year_month'] = df['created_at'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Ensure numeric types are correct\n",
    "for num_col in ['months_since_first_donation','number_of_donation','pints_donated']:\n",
    "    if num_col in df.columns:\n",
    "        df[num_col] = pd.to_numeric(df[num_col], errors='coerce').astype('Int64')\n",
    "\n",
    "# Save a cleaned, PII-stripped copy (optional artifact)\n",
    "clean_path = 'blood_donor_clean.csv'\n",
    "df.to_csv(clean_path, index=False)\n",
    "print('Saved cleaned dataset ->', clean_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d1fc1",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Exploratory Data Analysis (EDA)\n",
    "We look at distributions and simple relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Blood group distribution\n",
    "if 'blood_group' in df.columns:\n",
    "    bg_counts = df['blood_group'].value_counts().sort_index()\n",
    "    ax = bg_counts.plot(kind='bar')\n",
    "    ax.set_title('Blood Group Distribution')\n",
    "    ax.set_xlabel('Blood Group')\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87fd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Availability distribution\n",
    "if 'availability' in df.columns:\n",
    "    avail_counts = df['availability'].value_counts()\n",
    "    ax = avail_counts.plot(kind='bar')\n",
    "    ax.set_title('Availability (Yes/No)')\n",
    "    ax.set_xlabel('Availability')\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top cities\n",
    "if 'city' in df.columns:\n",
    "    city_counts = df['city'].value_counts().head(15)\n",
    "    ax = city_counts.plot(kind='bar')\n",
    "    ax.set_title('Top Cities by Donors')\n",
    "    ax.set_xlabel('City')\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Relationship: number_of_donation vs. pints_donated\n",
    "if all(c in df.columns for c in ['number_of_donation','pints_donated']):\n",
    "    ax = df.plot(kind='scatter', x='number_of_donation', y='pints_donated', alpha=0.5)\n",
    "    ax.set_title('Donations vs. Pints Donated')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Relationship: months_since_first_donation vs number_of_donation\n",
    "if all(c in df.columns for c in ['months_since_first_donation','number_of_donation']):\n",
    "    ax = df.plot(kind='scatter', x='months_since_first_donation', y='number_of_donation', alpha=0.5)\n",
    "    ax.set_title('Tenure (months) vs. Number of Donations')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea783b",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Time Series â€” Monthly New Donors (by `created_at`)\n",
    "We aggregate counts per month to analyze trends and forecast the next 12 months.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts = None\n",
    "if 'created_at' in df.columns and pd.api.types.is_datetime64_any_dtype(df['created_at']):\n",
    "    monthly = df.set_index('created_at').resample('MS')['donor_id' if 'donor_id' in df.columns else df.columns[0]].count()\n",
    "    monthly.name = 'new_donors'\n",
    "    ts = monthly\n",
    "    display(monthly.head())\n",
    "\n",
    "    ax = monthly.plot()\n",
    "    ax.set_title('Monthly New Donors')\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    # Seasonal decomposition (if long enough)\n",
    "    if len(monthly) >= 36:\n",
    "        result = seasonal_decompose(monthly, period=12, model='additive', extrapolate_trend='freq')\n",
    "        result.trend.plot(title='Trend')\n",
    "        plt.show()\n",
    "        result.seasonal.plot(title='Seasonality')\n",
    "        plt.show()\n",
    "        result.resid.plot(title='Residuals')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b22073",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Forecasting Next 12 Months (Exponential Smoothing)\n",
    "We hold out the last 12 months as test, fit an additive trend + seasonality model, evaluate, then refit on full data and forecast 12 months ahead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e96554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(a, f):\n",
    "    return sqrt(np.mean((np.array(a)-np.array(f))**2))\n",
    "\n",
    "forecast_path = 'monthly_new_donors_forecast.csv'\n",
    "\n",
    "if ts is not None and len(ts) >= 24:\n",
    "    train = ts.iloc[:-12]\n",
    "    test  = ts.iloc[-12:]\n",
    "\n",
    "    model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=12, initialization_method='estimated')\n",
    "    fit = model.fit(optimized=True)\n",
    "    pred = fit.forecast(12)\n",
    "\n",
    "    # Evaluation\n",
    "    eval_rmse = rmse(test.values, pred.values)\n",
    "    eval_mape = np.mean(np.abs((test.values - pred.values) / np.maximum(test.values, 1))) * 100.0\n",
    "    print({'RMSE': round(eval_rmse,2), 'MAPE_%': round(eval_mape,2)})\n",
    "\n",
    "    # Plot test vs forecast\n",
    "    ax = train.plot(label='train')\n",
    "    test.plot(ax=ax, label='test')\n",
    "    pred.plot(ax=ax, label='forecast')\n",
    "    ax.set_title('Holdout Test & Forecast (12 months)')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Refit full and forecast next 12\n",
    "    model_full = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=12, initialization_method='estimated')\n",
    "    fit_full = model_full.fit(optimized=True)\n",
    "    fcst = fit_full.forecast(12)\n",
    "\n",
    "    # Plot full series with forecast\n",
    "    ax = ts.plot(label='history')\n",
    "    fcst.plot(ax=ax, label='12â€‘mo forecast')\n",
    "    ax.set_title('Monthly New Donors â€” 12â€‘Month Forecast')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    out = pd.DataFrame({'month': fcst.index.to_period('M').astype(str), 'forecast_new_donors': fcst.values})\n",
    "    out.to_csv(forecast_path, index=False)\n",
    "    print('Saved forecast ->', forecast_path)\n",
    "else:\n",
    "    print('Not enough data to forecast.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aaea8e",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Predicting Donor Availability (Yes/No)\n",
    "\n",
    "We build two models:\n",
    "- **Logistic Regression** (interpretable baseline)\n",
    "- **Random Forest** (nonlinear baseline)\n",
    "\n",
    "**Target:** `availability` (Yes/No) **Features:** `months_since_first_donation`, `number_of_donation`, `pints_donated`, `blood_group`, `city` (when present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e56731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_col = 'availability'\n",
    "feature_cols = [c for c in ['months_since_first_donation','number_of_donation','pints_donated','blood_group','city'] if c in df.columns]\n",
    "\n",
    "if target_col in df.columns and feature_cols:\n",
    "    data = df[feature_cols + [target_col]].dropna().copy()\n",
    "    # Map target to binary\n",
    "    data[target_col] = data[target_col].map({'Yes':1, 'No':0}).astype(int)\n",
    "\n",
    "    X = data[feature_cols]\n",
    "    y = data[target_col]\n",
    "\n",
    "    numeric_features = [c for c in feature_cols if str(X[c].dtype)[:3] in ['int','flo']]\n",
    "    categorical_features = [c for c in feature_cols if c not in numeric_features]\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_SEED, stratify=y)\n",
    "\n",
    "    # Logistic Regression\n",
    "    logit = Pipeline(steps=[('pre', pre), ('clf', LogisticRegression(max_iter=1000))])\n",
    "    logit.fit(X_train, y_train)\n",
    "    preds_logit = logit.predict(X_test)\n",
    "    proba_logit = logit.predict_proba(X_test)[:,1]\n",
    "\n",
    "    print('Logistic Regression Metrics')\n",
    "    print(classification_report(y_test, preds_logit, digits=3))\n",
    "    print('ROC-AUC:', round(roc_auc_score(y_test, proba_logit), 3))\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_test, proba_logit)\n",
    "    plt.title('ROC Curve â€” Logistic Regression')\n",
    "    plt.show()\n",
    "\n",
    "    # Random Forest\n",
    "    rf = Pipeline(steps=[('pre', pre), ('clf', RandomForestClassifier(n_estimators=300, random_state=RANDOM_SEED))])\n",
    "    rf.fit(X_train, y_train)\n",
    "    preds_rf = rf.predict(X_test)\n",
    "    proba_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    print('Random Forest Metrics')\n",
    "    print(classification_report(y_test, preds_rf, digits=3))\n",
    "    print('ROC-AUC:', round(roc_auc_score(y_test, proba_rf), 3))\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_test, proba_rf)\n",
    "    plt.title('ROC Curve â€” Random Forest')\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importances (approximate, post-encoding)\n",
    "    # Extract from RF pipeline\n",
    "    rf_model = rf.named_steps['clf']\n",
    "    # After ColumnTransformer, get feature names:\n",
    "    oh_names = list(rf.named_steps['pre'].named_transformers_['onehot'].get_feature_names_out(categorical_features)) if categorical_features else []\n",
    "    final_feature_names = oh_names + numeric_features\n",
    "    importances = getattr(rf_model, 'feature_importances_', None)\n",
    "    if importances is not None:\n",
    "        imp_df = pd.DataFrame({'feature': final_feature_names, 'importance': importances}).sort_values('importance', ascending=False).head(20)\n",
    "        display(imp_df)\n",
    "        ax = imp_df.set_index('feature')['importance'].plot(kind='bar')\n",
    "        ax.set_title('Top Feature Importances â€” Random Forest')\n",
    "        ax.set_ylabel('Importance')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print('Availability prediction skipped (missing target/feature columns). Found features:', feature_cols, 'Target present?', target_col in df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee513c",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Save Artifacts\n",
    "\n",
    "- `blood_donor_clean.csv` â€” PII dropped, engineered fields\n",
    "- `monthly_new_donors_forecast.csv` â€” Next 12â€‘month forecast\n",
    "- You can also export models using `joblib` if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b235555",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "artifacts = {\n",
    "    'clean_csv': os.path.abspath('blood_donor_clean.csv') if os.path.exists('blood_donor_clean.csv') else None,\n",
    "    'forecast_csv': os.path.abspath('monthly_new_donors_forecast.csv') if os.path.exists('monthly_new_donors_forecast.csv') else None,\n",
    "    'rows_clean': int(len(df))\n",
    "}\n",
    "print(json.dumps(artifacts, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb827e5",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Conclusions & Next Steps\n",
    "- The notebook demonstrates a full workflow: **PII-safe cleaning â†’ EDA â†’ time-series forecasting â†’ availability prediction**.\n",
    "- Replace/extend features as needed (e.g., add recency of last donation if available).\n",
    "- Consider hyperparameter tuning (e.g., `RandomizedSearchCV`) and cross-validation for stronger leaderboard entries.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
